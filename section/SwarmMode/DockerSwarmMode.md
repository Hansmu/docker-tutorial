# Docker Swarm Mode

Docker Swarm mode is Docker‚Äôs native container orchestration system.
  
It allows you to run Docker containers across multiple machines (nodes) as a single logical cluster.

Swarm mode is built directly into Docker Engine ‚Äî no extra software is required.

---

## What problem does Swarm solve?

Running containers on a single machine is easy.

Running containers across multiple machines introduces new problems:
- How do containers find each other?
- What happens if a machine goes down?
- How do you scale services?
- How do you deploy updates without downtime?

Docker Swarm solves these problems by providing:
- clustering
- scheduling
- service discovery
- load balancing
- rolling updates
- fault tolerance

---

## Swarm vs standalone Docker

| Standalone Docker | Docker Swarm               |
|-------------------|----------------------------|
| Single host       | Multiple hosts             |
| `docker run`      | `docker service`           |
| Manual scaling    | Declarative scaling        |
| No built-in HA    | Built-in high availability |
| Containers        | Services & tasks           |

Swarm operates at the service level, not the container level.

This means that when dealing with Swarm, you no longer care about individual containers.

Services contain multiple containers.

The mental overhead of dealing with individual containers would be too high, so they're abstracted away in the form of services.

---

## Swarm architecture

A Swarm cluster consists of nodes. A node is a separate machine.

### Node types

#### Manager nodes
- Maintain cluster state
- Schedule services
- Handle orchestration decisions
- Participate in Raft consensus

#### Worker nodes
- Run containers (tasks)
- Do not make scheduling decisions
- Execute work assigned by managers

A single-node Swarm is possible, but production Swarms use multiple managers.

It is also possible for manager nodes to run containers, but this would only be the case in small swarms.
Ideally you'd want them to run only on workers.

When creating services, it is also possible to limit the containers to only run on workers:
```bash
docker service create \
  --name web \
  --constraint 'node.role==worker' \
  nginx
```

![Managers give orders to workers](image.png)

---

## Desired state model

Swarm uses a declarative desired-state model.

You declare:
> ‚ÄúI want 5 replicas of this service.‚Äù

Swarm continuously works to make reality match that declaration.

If:
- a container crashes
- a node goes offline

Swarm automatically replaces missing tasks (containers within the service).

---

## Services and tasks

### Service
A service defines:
- which image to run
- how many replicas to run
- how the service is exposed
- update strategy
- resource limits

For example:
```bash
docker service create --replicas 3 --name test-services busybox ping 8.8.8.8
```

### Task
A task is a single running container created to satisfy a service.

- One service ‚Üí many tasks
- Tasks are immutable
- Failed tasks are replaced, not restarted

![Services running multiple nodes](image-1.png)

---

## Creating a Swarm

```bash
docker swarm init
```

This:
* enables Swarm mode
* makes the node a manager
* creates a cluster

Other nodes join using a join token:

```bash
docker swarm join --token <token> <manager-ip>:2377
```

---

## Services vs containers

In Swarm mode, you normally do not use ``docker run``.

Instead, you use:

```bash
docker service create
```

Example:
```bash
docker service create --name web --replicas 3 -p 80:80 nginx
```

Swarm:
* schedules replicas across nodes
* load-balances traffic
* restarts failed tasks

---

## Scaling services

In case you want to change the number of replicas after initialization, then you can do so with a separate command.

Scaling is declarative:

```bash
docker service scale web=5
```

Swarm adds or removes tasks automatically.

---

## Built-in load balancing

Swarm provides two layers of load balancing:

1. Routing mesh (ingress)
   * Every node listens on the published port
   * Traffic is routed to any healthy task
   * Even if the task is on another node
2. Internal service discovery
   * Services get a virtual IP (VIP)
   * DNS-based discovery
   * Internal load balancing across tasks

![img.png](img.png)

The routing mesh is stateless, so no sticky sessions and such.

---

## Networking in Swarm

Swarm uses overlay networks:
* Span multiple hosts
* Encrypted (optional)
* Built-in DNS

Example:

```bash
docker network create --driver overlay app-net
```

Services attached to the same overlay network can:
* communicate by service name
  * note that service names are auto-generated by parts.
  * `<name>.<nr>.<ID>`
* be load-balanced automatically

---

## Volumes and data in Swarm

Persistent data is harder in Swarm.

Important points:
* Containers may run on any node
* Local volumes are node-specific
* Swarm does not automatically move data

Common solutions:
* network-attached storage
* volume plugins
* external databases

Best practice:

> Avoid stateful workloads in Swarm unless you understand the storage implications.

---

## Rolling updates

Swarm supports rolling updates out of the box.

Example:

```bash
docker service update --image my-app:v2 web
```

You can control:
* update parallelism
* delay between updates
* failure behavior

This enables zero-downtime deployments.

---

## Health checks

If a container becomes unhealthy:
* Swarm marks the task as failed
* A new task is scheduled automatically

Health checks are defined in the image:

```bash
HEALTHCHECK CMD curl -f http://localhost || exit 1
```

---

## Stacks

A stack in Docker Swarm is a collection of related services, networks, and volumes that are defined together (usually in a Compose file) and deployed as a single unit to the swarm.

Think of a stack as ‚ÄúCompose for Swarm‚Äù.

A stack lets you say:

‚ÄúThese services belong together, share networks, and should be deployed and managed as one application.‚Äù

Instead of creating services one by one, you define everything declaratively and deploy it in one command.

Stacks are deployed using:

```bash
docker stack deploy -c docker-compose.yml my-stack
```

What happens:
* The command must run on a manager
* Docker reads the Compose file (v3+ format)
* Docker creates:
  * Services 
  * Overlay networks 
  * Volumes 
* All resources are namespaced under the stack name

Example service name:
```
my-stack_web
my-stack_api
```

You can re-use a Compose file for it.

When you're running Compose, then it'll ignore the `deploy` section.

When you're running Stacks, then it'll ignore the `build` section.

### Example stack file (minimal)
```yaml
version: "3.9"

services:
   web:
      image: nginx:alpine
      ports:
      - "80:80"
      deploy:
        replicas: 2
        placement:
          constraints:
            - node.role == worker

   api:
      image: my-api:latest
      deploy:
        replicas: 3

networks:
   default:
    driver: overlay
```

Deploy it:

```bash
docker stack deploy -c docker-compose.yml my-stack
```

### What stacks give you (and why they matter)
#### üì¶ Grouping & lifecycle management
* Deploy the whole app at once
* Update everything together
* Remove everything together:

```bash
docker stack rm my-stack
```

![img_1.png](img_1.png)
---

## Secrets and configs

Swarm has built-in secrets management.

Secrets:
* stored encrypted
* mounted into containers at runtime
* never baked into images

Example:

```bash
docker secret create db_password password.txt
```

---

## High availability

For production:
* use odd numbers of manager nodes
* typically 3 or 5
* ensures Raft quorum

If quorum is lost:
* cluster becomes read-only
* existing services keep running
* no new scheduling decisions

---

## Swarm vs Docker Compose

| Docker Compose      | Docker Swarm          |
| ------------------- | --------------------- |
| Single host         | Multi-host            |
| Development-focused | Production-capable    |
| No HA               | Built-in HA           |
| No scheduler        | Distributed scheduler |

Swarm uses Compose-style files, but behavior differs.

---

## When to use Docker Swarm

Good use cases:
* Small to medium clusters
* Teams already familiar with Docker
* Simple production orchestration
* Learning orchestration concepts

Not ideal when:
* You need advanced scheduling
* You need complex networking policies
* You already use Kubernetes
* You need a large ecosystem

---

## Swarm vs Kubernetes (high-level)

* Swarm is simpler and easier to learn
* Kubernetes is more powerful and extensible
* Swarm has minimal ecosystem growth
* Kubernetes dominates industry adoption
* Swarm is still useful as a learning bridge.

---

## Key takeaways

* Swarm is Docker‚Äôs built-in orchestrator
* Operates on services, not containers
* Uses desired-state reconciliation
* Provides networking, load balancing, scaling
* Simpler than Kubernetes, less powerful
* Still valuable for understanding orchestration